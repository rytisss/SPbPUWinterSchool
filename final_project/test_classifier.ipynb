{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_image_from_dir(input_dir):\n",
    "    image_extensions = ['*.bmp', '*.jpg', '*.png']\n",
    "    image_list = []\n",
    "    for image_extension in image_extensions:\n",
    "        image_list.extend(glob.glob(input_dir + image_extension))\n",
    "    image_list.sort()\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_image_to_screen(image, screen_width=1920, screen_height=1080, scale=0.5):\n",
    "    \"\"\"Returns resized, fit to the screen image\"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    width_scale = float(screen_width) / float(width)\n",
    "    height_scale = float(screen_height) / float(height)\n",
    "    # if image fits to desired screen size, do not resize\n",
    "    if width_scale > 1.0:\n",
    "        width_scale = 1.0\n",
    "    if height_scale > 1.0:\n",
    "        height_scale = 1.0\n",
    "    image_scale = height_scale if width_scale > height_scale else width_scale\n",
    "    image_scale *= scale\n",
    "    resized_image = cv2.resize(image, (0, 0), fx=image_scale, fy=image_scale)\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    # normalize image and make 'tensor-like'\n",
    "    norm_image = image / 255\n",
    "    norm_image_norm = np.reshape(norm_image, (1,) + norm_image.shape)\n",
    "    return norm_image_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_extrapolate_image_boarders(image, destination_width, destination_height):\n",
    "    \"\"\"\n",
    "    resize to fit image and make boarders\n",
    "    \"\"\"\n",
    "    # resize 'imageROI' to fit into destination image, also keep the aspect ratio\n",
    "    roi_height, roi_width = image.shape[:2]\n",
    "    x_aspect_ratio = destination_width / roi_width\n",
    "    y_aspect_ratio = destination_height / roi_height\n",
    "    resize_ratio = x_aspect_ratio if x_aspect_ratio < y_aspect_ratio else y_aspect_ratio\n",
    "    resized_width = int(resize_ratio * float(roi_width))\n",
    "    resized_height = int(resize_ratio * float(roi_height))\n",
    "    # prevention from too big width\n",
    "    if resized_width > destination_width:\n",
    "        resized_width = destination_width\n",
    "    if resized_height > destination_height:\n",
    "        resized_height = destination_height\n",
    "    delta_w = destination_width - resized_width\n",
    "    delta_h = destination_height - resized_height\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "    resized_roi = cv2.resize(image, (resized_width, resized_height))\n",
    "    # calculate offset for roi in image (roi is centered)\n",
    "    \"\"\"\n",
    "    resized_roi_height, resized_roi_width = resized_roi.shape[:2]\n",
    "    x_offset = int((destination_width - resized_roi_width) / 2)\n",
    "    y_offset = int((destination_height - resized_roi_height) / 2)\n",
    "    destination_image[y_offset:y_offset+resized_roi_height, x_offset:x_offset+resized_roi_width] = resized_roi\n",
    "    \"\"\"\n",
    "    destination_image = cv2.copyMakeBorder(resized_roi, top, bottom, left, right, cv2.BORDER_REPLICATE, None, [0, 0, 0])\n",
    "    return destination_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_MobileNetV3Small_model(input_size=(224, 224, 3), weigths_path=None):\n",
    "    base = tf.keras.applications.MobileNetV3Small(include_top=False,\n",
    "                                                  weights='imagenet',\n",
    "                                                  input_shape=input_size)\n",
    "    base.trainable = True\n",
    "    model = tf.keras.Sequential([\n",
    "        base,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    # Draw model graph\n",
    "    #tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  optimizer=Adam(lr=1e-3),\n",
    "                  metrics=['binary_accuracy'])\n",
    "\n",
    "    if weigths_path != None:\n",
    "        model.load_weights(weigths_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what animal it is from prediction\n",
    "def cat_or_dog(prediction):\n",
    "    animal = ''\n",
    "    if prediction[0][0] >= 0.5:\n",
    "        animal = 'dog'\n",
    "    else:\n",
    "        animal = 'cat'\n",
    "    return animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat | model output: 0.0859477\n",
      "cat | model output: 0.1125396\n",
      "cat | model output: 0.1290707\n",
      "cat | model output: 5.72139e-07\n",
      "cat | model output: 0.017000675\n",
      "dog | model output: 1.0\n",
      "dog | model output: 0.999997\n",
      "dog | model output: 0.99987686\n",
      "cat | model output: 2.9096198e-10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# reset tensorflow values\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "test_image_dir = 'test_images/'\n",
    "trained_weights = 'weights/Doggo_or_catto-007-0.0087.hdf5'\n",
    "model = create_MobileNetV3Small_model(weigths_path=trained_weights)\n",
    "input_size = (224, 224)\n",
    "# test directory contains folder with different classes\n",
    "# collect those subdirectory with different numbers\n",
    "image_paths = gather_image_from_dir(test_image_dir)\n",
    "for image_path in image_paths:\n",
    "    image = cv2.imread(image_path)\n",
    "    image_preprocessed = resize_and_extrapolate_image_boarders(image, input_size[0], input_size[0])\n",
    "    image_rb_invert = cv2.cvtColor(image_preprocessed, cv2.COLOR_BGR2RGB)\n",
    "    image_rb_invert_tensor = preprocess_image(image_rb_invert)\n",
    "    prediction = model.predict(image_rb_invert_tensor)\n",
    "    cv2.imshow('original_image', fit_image_to_screen(image))\n",
    "    cv2.imshow('preprocessed_image', image_preprocessed)\n",
    "    animal = cat_or_dog(prediction)\n",
    "    print(animal + ' | model output: ' + str(prediction[0][0]))\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
